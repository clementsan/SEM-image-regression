{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression + Classification  - ResNet50 with K-fold - L2loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup CUDA_VISIBLE DEVICES for titan.sci.utah.edu\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains all the main external libs we'll use\n",
    "from fastai.imports import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.plots import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import *\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../data/\"\n",
    "sz=224\n",
    "arch=resnet50\n",
    "bs=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV for classification task\n",
    "Classification_csv = f'{PATH}Dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_df = pd.read_csv(Classification_csv)\n",
    "Classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV for regresssion task\n",
    "Regression_csv = f'{PATH}Dataset_Regression.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression_df = pd.read_csv(Regression_csv)\n",
    "Regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation indices\n",
    "\n",
    "n = len(list(open(Regression_csv)))-1\n",
    "# Return validation indexes using a 10% split\n",
    "val_idxs = get_cv_idxs(n,val_pct=0.1)\n",
    "print('n:',n)\n",
    "print('Nb val_idxs',len(val_idxs))\n",
    "print('val_idxs',val_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression dataset\n",
    "md = ImageClassifierData.from_csv(PATH, 'data_all', Regression_csv, tfms=tfms, continuous=True, \n",
    "   bs=bs, val_idxs=val_idxs, num_workers = 0)\n",
    "\n",
    "# Define classification dataset\n",
    "md2 = ImageClassifierData.from_csv(PATH, 'data_all', Classification_csv, tfms=tfms, continuous=False, \n",
    "   bs=bs, val_idxs=val_idxs, num_workers = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatLblDataset(Dataset):\n",
    "    def __init__(self, ds, y2): self.ds,self.y2 = ds,y2\n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x,y = self.ds[i]\n",
    "        return (x, (y,self.y2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine datasets\n",
    "trn_ds2 = ConcatLblDataset(md.trn_ds, md2.trn_y)\n",
    "val_ds2 = ConcatLblDataset(md.val_ds, md2.val_y)\n",
    "\n",
    "md.trn_dl.dataset = trn_ds2\n",
    "md.val_dl.dataset = val_ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_reg = nn.Sequential(\n",
    "    AdaptiveConcatPool2d(),\n",
    "    Flatten(),\n",
    "    nn.BatchNorm1d(4096),\n",
    "    nn.Dropout(0.25),\n",
    "    nn.Linear(4096,1+5),\n",
    ")\n",
    "\n",
    "models = ConvnetBuilder(arch, 0, 0, 0, custom_head=head_reg)\n",
    "\n",
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn = optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to run for this notebook\n",
    "# Adaptation from \"pascal_Clem\" notebook\n",
    "def detn_loss(input, target):\n",
    "    r_t,c_t = target\n",
    "    r_i,c_i = input[:, :1], input[:, 1:]\n",
    "    r_i = F.sigmoid(r_i)*200+600\n",
    "    # I looked at these quantities separately first then picked a multiplier\n",
    "    #   to make them approximately equal\n",
    "    #print('r_t',r_t)\n",
    "    #print('c_t',c_t)\n",
    "    #print('r_i',r_i)\n",
    "    #print('c_i',c_i)\n",
    "    #print('\\nL1_loss',F.l1_loss(r_i, r_t))\n",
    "    #print('Cross_entropy loss',F.cross_entropy(c_i, c_t))\n",
    "    return F.mse_loss(r_i, r_t) + (F.cross_entropy(c_i, c_t)*1000)\n",
    "\n",
    "\n",
    "def detn_l2(input, target):\n",
    "    r_t,_ = target\n",
    "    r_i = input[:, :1]\n",
    "    r_i = F.sigmoid(r_i)*200+600\n",
    "    #print('r_i',r_i)\n",
    "    #print('r_t',r_t)\n",
    "    return F.mse_loss(V(r_i),V(r_t)).data\n",
    "\n",
    "def detn_acc(input, target):\n",
    "    _,c_t = target\n",
    "    c_i = input[:, 1:]\n",
    "    #print('c_i',V(c_i))\n",
    "    #print('c_t',V(c_t))\n",
    "    #return V(C_i)\n",
    "    # Code from Clem\n",
    "    #preds = np.argmax(V(c_i), 1)\n",
    "    return accuracy_np(to_np(c_i), to_np(c_t))\n",
    "    #return (preds==V(c_t)).mean()\n",
    "\n",
    "learn.crit = detn_loss\n",
    "learn.metrics = [detn_l2, detn_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf=learn.lr_find(end_lr=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot(n_skip = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-3\n",
    "learn.fit(lr, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(lr, 5, cycle_len = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "lr = 1e-3\n",
    "lrs=np.array([lr/9,lr/3,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf=learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.sched.plot(n_skip=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lrs=np.array([lr/9,lr/3,lr])\n",
    "learn.fit(lrs, 5, cycle_len = 1, cycle_mult = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "\n",
    "List_MAE = []\n",
    "#List_RMSE = []\n",
    "#List_R2 = []\n",
    "List_Acc = []\n",
    "\n",
    "KFold_Iteration = 0\n",
    "\n",
    "# K-fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state = 1)\n",
    "\n",
    "for train_index, val_index in kf.split(Classification_df.index):\n",
    "    print(\"\\n\\nKFold_Iteration\", KFold_Iteration)\n",
    "    print(\"\\nLength training\",len(train_index))\n",
    "    print(\"Length validation\",len(val_index))\n",
    "    \n",
    "    tfms = tfms_from_model(arch, sz, aug_tfms=transforms_side_on)\n",
    "    \n",
    "    # Define regression dataset\n",
    "    md = ImageClassifierData.from_csv(PATH, 'data_all', Regression_csv, tfms=tfms, continuous=True, \n",
    "        bs=bs, val_idxs=val_index, num_workers = 0)\n",
    "    \n",
    "    # Define classification dataset\n",
    "    md2 = ImageClassifierData.from_csv(PATH, 'data_all', Classification_csv, tfms=tfms, continuous=False, \n",
    "        bs=bs, val_idxs=val_index, num_workers = 0)\n",
    "    \n",
    "    # Combine datasets\n",
    "    trn_ds2 = ConcatLblDataset(md.trn_ds, md2.trn_y)\n",
    "    val_ds2 = ConcatLblDataset(md.val_ds, md2.val_y)\n",
    "    md.trn_dl.dataset = trn_ds2\n",
    "    md.val_dl.dataset = val_ds2\n",
    "    \n",
    "    # Add  model\n",
    "    head_reg = nn.Sequential(\n",
    "        AdaptiveConcatPool2d(),\n",
    "        Flatten(),\n",
    "        nn.BatchNorm1d(4096),\n",
    "        nn.Dropout(0.25),\n",
    "        nn.Linear(4096,1+5),\n",
    "    )\n",
    "    \n",
    "    models = ConvnetBuilder(arch, 0, 0, 0, custom_head=head_reg)\n",
    "    \n",
    "    learn = ConvLearner(md, models)\n",
    "    # Update optimizer and loss function\n",
    "    learn.opt_fn = optim.Adam\n",
    "    learn.crit = detn_loss\n",
    "    learn.metrics = [detn_l2, detn_acc]\n",
    "    \n",
    "    print(\"Optimizing Last layer only...\")\n",
    "    lr = 2e-3\n",
    "    learn.fit(lr, 5)\n",
    "    #learn.precompute=False\n",
    "    learn.fit(lr, 5, cycle_len=1)\n",
    "    print(\"\\nOptimizing full model...\")\n",
    "    learn.unfreeze()\n",
    "    # New learning rate\n",
    "    lr = 1e-3\n",
    "    lrs=np.array([lr/9,lr/3,lr])\n",
    "    result = learn.fit(lrs, 5, cycle_len=1, cycle_mult=2)\n",
    "    \n",
    "    MAE = result[1]\n",
    "    Acc = result[2]\n",
    "    \n",
    "    print('MAE', MAE)\n",
    "    List_MAE.append(MAE)\n",
    "    \n",
    "    print('Acc', Acc)\n",
    "    List_Acc.append(Acc)\n",
    "    \n",
    "    KFold_Iteration += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nResults overview\")\n",
    "MAE_avg = np.average(List_MAE)\n",
    "MAE_std = np.std(List_MAE)\n",
    "print(\"MAE_avg\",MAE_avg)\n",
    "print(\"MAE_std\",MAE_std)\n",
    "\n",
    "\n",
    "Acc_avg = np.average(List_Acc)\n",
    "Acc_std = np.std(List_Acc)\n",
    "print(\"Acc_avg\",Acc_avg)\n",
    "print(\"Acc_std\",Acc_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "266px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
